## The Stack
Remember how I told you that memory is basically just a giant array of bytes with addresses at various offsets?

That's true, but it also has some additional structure. In particular, memory is divided into two main regions: the **stack** and the **heap**. We'll cover the heap later.

The stack is where local variables are stored. When a function is called, a new **stack frame** is created in memory to store the function's parameters and local variables. When the function returns, it's entire stack frame is deallocated.

The stack is aptly named: it is **stack** (the "Last in, First out" data structure) of memory frames. Each time a function is called, a new frame is pushed onto the stack. When the function returns. its frame is popped of the stack.

Take a look at this example function:

```c
void create_typist(int uses_nvim) {
  int wpm = 150;
  char name[4] = {'t', 'e', 'e', 'j'};
}
```

Say we call `create_typist(1)`. Before the call, our stack memory might look like this, with next memory address to be used `0xFEFC`:

![](attachments/Pasted%20image%2020241004235758.png)

Once called, the <u>stack pointer</u> is moved to make room for:
- The return address (to pick up execution after the function returns)
- Arguments to the function
- Local variables in the function body

![](attachments/Pasted%20image%2020241004235802.png)

and the local variables are stored in the stack frame:

![](attachments/Pasted%20image%2020241004235808.png)

When the function returns, the stack frame is deallocated by resetting the stack pointer to where the frame begin.

## Why a Stack?
Allocating memory on the stack is preferred when possible because the stack is faster and simpler than the heap (which we'll get to, be patient):
- **Efficient Pointer Management:** Stack "allocation" is just a quick increment or decrement of the stack pointer, which is extremely fast. Heap allocations require more complex bookkeeping.
- **Cache-Friendly Memory Access:** Stack memory is stored in a contiguous block, enhancing cache performance due to spatial locality.
- **Automatic Memory Management:** Stack memory is managed automatically as functions are called and as they return.
- **Inherent Thread Safety**: Each thread has its own stack. Heap allocations require synchronization mechanisms when used concurrently, potentially introducing overhead. 

> [!NOTE] 
> One reason Go programs are efficient is that Go uses stack allocation for variables when possible, much like C. The Go compiler performs escape analysis to decide whether a variable can be allocated on the stack. On the other hand, languages like Python allocate most objects on the heap, which can impact performance.


## Stack Overflow
So the stack is great and all, but one of the downsides is that it has a limited size. If you keep pushing frames onto the stack without popping them off, you'll eventually run out of memory and get a <u>stack overflow</u>. 

That's one of the reasons recursion without <u>tail-call-optimization</u> can be dangerous. Each recursive call pushes onto the stack, and if you have too many recursive, you'll run out of stack space.

## Pointers to the Stack
So we know that stack frames are always getting pushed and popped, and as a result, memory addresses on the stack are always changing and getting reused.

*Remember: the stack is only safe to use within the context of the current function!*

## The Heap
<u>"The heap"</u> , as opposed to "the stack", is a pool of long-lived memory shared across the entire program. Stack memory is automatically allocated and deallocated as functions are called and return, but heap memory is allocated and deallocated as needed, independent of the burdensome shackles of function calls.

When you need to store data that outlives the function that created it, you'll send it to the heap. The heap is called "dynamic memory" because it's allocated and deallocated as needed. Take a look at `new_int_array`:

```c
int *new_int_array(int size) {
  int *new_arr = (int*)malloc(size * sizeof(int)); // Allocate memory
  if (new_arr == NULL) {
    fprintf(stderr, "Memory allocation failed\n");
    exit(1); // Exit if allocation fails
  }
  return new_arr;
}
```

Because size of the array isn't known at compile time, we cant't put it on the stack. Instead, we allocated memory on the heap using the `<stdlib.h>`'s `malloc` function. It takes a number of bytes to allocated as an argument (`size * sizeof(int)`) and returns a pointer to the allocated memory (a `void *` that we cast to an `int *`). Here's a diagram of what happened in memory:

![](attachments/Pasted%20image%2020241004235823.png)

The `new_int_array` function's `size` argument is just an integer, it's pushed onto the stack. Assuming `size` is `6`, when `malloc` is called we're given enough memory to store 6 integers on the heap, and we're given the address of the start of that newly allocated memory. We store it in a new local variable called `new_arr`. The address is store on the stack, but the data it points to is in the heap.

Let's look at some code that uses `new_int_array`:

```c
int* arr_of_6 = new_int_array(6);
arr_of_6[0] = 69;
arr_of_6[1] = 42;
arr_of_6[2] = 420;
arr_of_6[3] = 1337;
arr_of_6[4] = 7;
arr_of_6[5] = 0;
```

The data is stored in the heap: 

![](attachments/Pasted%20image%2020241004235829.png)

When we're done with the memory, we need to manually deallocated it using the `<stdlib.h>`'s `free` function:

```c
free(arr_of_6);
```

![](attachments/Pasted%20image%2020241004235832.png)

The `free` function returns (deallocates) that memory for use elsewhere. It's important to note that the pointer (`arr_of_6`) still exists, but shouldn't be used. It's a "dangling pointer", pointing to deallocated memory.

## Malloc 
The `malloc` function (`m`emory `alloc`ation) is a standard library function is C that allocates a specified number of bytes in memory on the heap and returns a pointer to the allocated memory.

The new memory is **uninitialized**, which means:
- It contains whatever data was previously at that location.
- It is the programmer's responsibility to ensure that the allocated memory is properly initialized and eventually freed using `free` to avoid memory leaks.

If you want to make sure that the memory is properly initialized, you can used the `calloc` function, which allocates the specified number of bytes of memory on the heap and returns a pointer to the allocated memory. This memory is initialized to zero (meaning it contains all zeroes). 

### Function Signature

```c
void* malloc(size_t size);
```

- `size`: The number of bytes to allocate.
- Returns: A pointer to the allocated memory or `NULL` if the allocation fails.
\
### Example Usage

```c
// Allocates memory for an array of 4 integers
int *ptr = malloc(4 * sizeof(int));
if (ptr == NULL) {
  // Handle memory allocation failure
  printf("Memory allocation failed\n");
  exit(1);
}
// use the memory here
// ...
free(ptr);
```

### Manual Memory Management
This idea of manually calling `malloc` and `free` is what puts the "manual" in "manually managing memory":
- The programmer must remember to eventually free the allocated memory using `free(ptr)` to avoid memory leaks.
- Otherwise, that allocated memory is never returned to the operating system for use by other programs, (Until the program exits, at which point the operating system will clean up after it, but that's not ideal.)
Manually managing memory can be error-prone and tedious, but languages that automatically manage memory (like Python, Java, and C#) have their own trade-offs, usually in terms of performance/1

## Free
The `free` function deallocates memory that was previously allocated by `malloc`, `calloc`, or `realloc`.

> [!IMPORTANT]
> `free` doesn't change the **value** stored in the memory, and it doesn't even change the address stored in the pointer. Instead, it simply informs the Operating System that the memory can be used again.

### Forgetting to free
Forgetting to call `free` leads to a memory leak. This means that the allocated memory remains occupied and cannot be reused, even though the program no longer needs it. Over time, if a program continues to allocate memory without freeing it, the program may run out of memory and crash.

Memory leaks are one of the common bugs in C programs, and they can be difficult to track down because the memory is still allocated and accessible, even though it is no longer needed.

## Big Endian and Little Endian
While we are on the topic of memory, it's worth knowing about "endianness". Endianness is the order in which bytes are stored in memory. The two most common formats are big endian and little endian.

### Big Endian
In a big-endian system, the most significant byte is stored first, at the lowest memory address. The "most significant byte" is just a fancy way of saying "the biggest part of the number".

Let's say you have the hexadecimal number `0x12345678`. Here's how it would be stored in big-endian format:

![](attachments/Pasted%20image%2020241004235848.png)

### Little Endian
In a little-endian system, the least significant byte (the "smallest" part of the number) is stored first, at the lowest memory address. This is the format used by most modern computers.

Using the same number `0x12345678`, here's how it would be stored in the little-endian format:

![](attachments/Pasted%20image%2020241004235852.png)

Here, the least significant byte (`0x78`) is stored first.

For the most part, you won't have to worry about endianness when writing programs. The way data is read from memory automatically handles this, so we can spend our valuable time building e-commerce shops for the terminal instead. Endianness becomes important in certain scenarios, like networking and working with binary files.

For now, just know that most modern systems use little-endian, and the compiler takes care of how data is stored and accessed.

> [!NOTE]
> The little-endian system has the property that the same value can be read from memory at different lengths without using different addresses.

